{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calibrating GPs using ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignore all the iris warnings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cis\n",
    "import iris\n",
    "\n",
    "from utils import get_aeronet_data, get_bc_ppe_data\n",
    "\n",
    "from esem.utils import validation_plot, plot_parameter_space, get_random_params, ensemble_collocate\n",
    "from esem import gp_model\n",
    "from esem.abc_sampler import ABCSampler, constrain\n",
    "\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the parameters and observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaod = get_aeronet_data()\n",
    "print(aaod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the PPE parameters, AAOD and DRE\n",
    "ppe_params, ppe_aaod, ppe_dre = get_bc_ppe_data(dre=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the annual mean of the DRE\n",
    "ppe_dre, = ppe_dre.collapsed('time', iris.analysis.MEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocate the model on to the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ppe_aaod = ensemble_collocate(ppe_aaod, aaod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 8\n",
    "\n",
    "X_test, X_train = ppe_params[:n_test], ppe_params[n_test:]\n",
    "Y_test, Y_train = col_ppe_aaod[:n_test], col_ppe_aaod[n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore different model choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esem.utils import leave_one_out, prediction_within_ci\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from esem.data_processors import Log\n",
    "res_l = leave_one_out(X_train, Y_train, model='GaussianProcess', data_processors=[Log(constant=0.1)], kernel=['Linear', 'Exponential', 'Bias'])\n",
    "r2_values_l = [stats.linregress(x.data.compressed(), y.data[:, ~x.data.mask].flatten())[2]**2 for x,y,_ in res_l]\n",
    "ci95_values_l = [prediction_within_ci(x.data.flatten(), y.data.flatten(), v.data.flatten())[2].sum()/x.data.count() for x,y,v in res_l]\n",
    "print(\"Mean R^2: {:.2f}\".format(np.asarray(r2_values_l).mean()))\n",
    "print(\"Mean proportion within 95% CI: {:.2f}\".format(np.asarray(ci95_values_l).mean()))\n",
    "\n",
    "res = leave_one_out(X_train, Y_train, model='GaussianProcess', kernel=['Linear', 'Bias'])\n",
    "r2_values = [stats.linregress(x.data.flatten(), y.data.flatten())[2]**2 for x,y,v in res]\n",
    "ci95_values = [prediction_within_ci(x.data.flatten(), y.data.flatten(), v.data.flatten())[2].sum()/x.data.count() for x,y,v in res]\n",
    "print(\"Mean R^2: {:.2f}\".format(np.asarray(r2_values).mean()))\n",
    "print(\"Mean proportion within 95% CI: {:.2f}\".format(np.asarray(ci95_values).mean()))\n",
    "\n",
    "# Note that while the Log pre-processing leads to slightly better R^2, the model is under-confident and\n",
    "#  has too large uncertainties which would adversley effec our implausibility metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp_model(X_train, Y_train, kernel=['Linear', 'Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_plot(Y_test.data.flatten(), m.data.flatten(), v.data.flatten(),\n",
    "               minx=0, maxx=0.1, miny=0., maxy=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample and constrain the models\n",
    "\n",
    "Emulating 1e6 sample points directly would require 673 Gb of memory so we can either run 1e6 samples for each point, or run the constraint everywhere, but in batches. Here we do the latter, optioanlly on the GPU, using the 'naive' algorithm for calculating the running mean and variance of the various properties. \n",
    "\n",
    "The rejection sampling happens in a similar manner so that only as much memory as is used for one batch is ever used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case \n",
    "sample_points = pd.DataFrame(data=get_random_params(3, int(1e6)), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that smoothing the parameter distribution can be slow for large numbers of points\n",
    "plot_parameter_space(sample_points, fig_size=(3,6), smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the sampler to compare against our AeroNet data\n",
    "sampler = ABCSampler(model, aaod, obs_uncertainty=0.5, repres_uncertainty=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the implausibilty for each sample against each observation - note this can be very large so we only sample a fraction!\n",
    "implaus = sampler.get_implausibility(sample_points[::100], batch_size=1000)\n",
    "\n",
    "# The implausibility distributions for different observations can be very different.\n",
    "_ = plt.hist(implaus.data[:, 1400])\n",
    "_ = plt.hist(implaus.data[:, 14])\n",
    "plt.gca().set(xlabel='Implausibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the valid samples in our full 1million samples by comparing against a given tolerance and threshold\n",
    "valid_samples = sampler.batch_constrain(sample_points, batch_size=10000, tolerance=.1)\n",
    "print(\"Remaining points: {}\".format(valid_samples.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reduced parameter distribution\n",
    "constrained_sample = sample_points[valid_samples]\n",
    "plot_parameter_space(constrained_sample, fig_size=(3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also easily plot the joint distributions\n",
    "#  Only plot every one in 100 points as scatter plots with large numbers of points are slow...\n",
    "import matplotlib\n",
    "\n",
    "# Mimic Seaborn scaling without requiring the whole package\n",
    "scale = 1.5\n",
    "matplotlib.rcParams['font.size'] = 12 * scale\n",
    "matplotlib.rcParams['axes.labelsize'] = 12 * scale\n",
    "matplotlib.rcParams['axes.titlesize'] = 12 * scale\n",
    "matplotlib.rcParams['xtick.labelsize'] = 11 * scale\n",
    "matplotlib.rcParams['ytick.labelsize'] = 11 * scale\n",
    "matplotlib.rcParams['lines.linewidth'] = 1.5 * scale\n",
    "matplotlib.rcParams['lines.markersize'] = 6 * scale\n",
    "# \n",
    "\n",
    "m, _ = model.predict(constrained_sample[::100].values)\n",
    "Zs = m.data\n",
    "# Plot the emulated AAOD value (averaged over observation locations) for each point\n",
    "grr = pd.plotting.scatter_matrix(constrained_sample[::100], c=Zs.mean(axis=1), figsize=(12, 10), marker='o',\n",
    "                                 hist_kwds={'bins': 20,}, s=20, alpha=.8, vmin=1e-3, vmax=1e-2, range_padding=0.,\n",
    "                                 density_kwds={'range': [[0., 1.], [0., 1.]], 'colormap':'viridis'},\n",
    "                                 )\n",
    "\n",
    "# Matplotlib dragons...\n",
    "grr[0][0].set_yticklabels([0.2, 0.4, 0.6, 0.8], fontsize=12 * scale)\n",
    "for i in range(2):\n",
    "    grr[i+1][0].set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8], fontsize=12 * scale)\n",
    "for i in range(3):\n",
    "    grr[2][i].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8])\n",
    "    grr[2][i].set_xticklabels([0.0, 0.2, 0.4, 0.6, 0.8], fontsize=12 * scale)\n",
    "\n",
    "plt.colorbar(grr[0][1].collections[0], ax=grr, use_gridspec=True, label='AAOD (1)')\n",
    "\n",
    "plt.savefig('BCPPE_constrained_params_paper.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the uncertainty in Direct Radiative Effect of Aerosol in constrianed sample-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dre_test, dre_train = ppe_dre[:n_test], ppe_dre[n_test:]\n",
    "\n",
    "ari_model = gp_model(X_train, dre_train, name=\"ARI\", kernel=['Linear', 'Bias'])\n",
    "ari_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std-dev DRE over each set of sample points\n",
    "\n",
    "unconstrained_mean_ari, unconstrained_sd_ari = ari_model.batch_stats(sample_points, batch_size=10000)\n",
    "constrained_mean_ari, constrained_sd_ari = ari_model.batch_stats(constrained_sample, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original (unconstrained DRE)\n",
    "qplt.pcolormesh(unconstrained_sd_ari, vmin=0., vmax=1)\n",
    "plt.gca().coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constrained DRE\n",
    "qplt.pcolormesh(constrained_sd_ari, vmin=0., vmax=1)\n",
    "plt.gca().coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The change in spread after the constraint is applied\n",
    "qplt.pcolormesh((constrained_sd_ari-unconstrained_sd_ari), cmap='RdBu_r', vmin=-5e-1, vmax=5e-1)\n",
    "plt.gca().coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edcc89b55b979b95119a99ed0f1da949018b8559dd23c0cb0696abeee4d47127"
  },
  "kernelspec": {
   "display_name": "Python [conda env:climatebench]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
